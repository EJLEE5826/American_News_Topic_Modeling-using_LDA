{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling using LDA\n",
    "\n",
    "reference : https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora, models\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "f = open(\"new_conserv.txt\", 'r', encoding = \"UTF8\")\n",
    "# 데이터 받아옴\n",
    "dataset = []\n",
    "while True:\n",
    "    line = f.readline()\n",
    "    if not line: break\n",
    "    dataset += [line.split(' ')]\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dictionary size : 63421\n"
     ]
    }
   ],
   "source": [
    "dct = gensim.corpora.Dictionary(dataset)\n",
    "print('dictionary size : %d' % len(dct))\n",
    "\n",
    "corpus = [dct.doc2bow(line) for line in dataset]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.05218122637145137),\n",
      " (1, 0.15909716552660308),\n",
      " (2, 0.08317410594517079),\n",
      " (3, 0.08832725321536473),\n",
      " (4, 0.17628174432034432),\n",
      " (5, 0.23923159705953712),\n",
      " (6, 0.15131111963341945),\n",
      " (7, 0.13599213937203022),\n",
      " (8, 0.09832815921436736),\n",
      " (9, 0.06849429969318149),\n",
      " (10, 0.08938413447461928),\n",
      " (11, 0.14256709573329698),\n",
      " (12, 0.06620976242309624),\n",
      " (13, 0.03672592923230124),\n",
      " (14, 0.09666135921451371),\n",
      " (15, 0.14989903675512392),\n",
      " (16, 0.05530982028256249),\n",
      " (17, 0.09377120877754128),\n",
      " (18, 0.09675570509992226),\n",
      " (19, 0.19351141019984452),\n",
      " (20, 0.06750909630801802),\n",
      " (21, 0.07295323186454916),\n",
      " (22, 0.08386344558939009),\n",
      " (23, 0.06421362714752624),\n",
      " (24, 0.3220711363883548),\n",
      " (25, 0.1373449291401259),\n",
      " (26, 0.0728511170846625),\n",
      " (27, 0.05952447402379828),\n",
      " (28, 0.05783192713705242),\n",
      " (29, 0.03956311296162247),\n",
      " (30, 0.10257538802657626),\n",
      " (31, 0.1443809734143166),\n",
      " (32, 0.0596607125651638),\n",
      " (33, 0.14026322394139062),\n",
      " (34, 0.16583692455378596),\n",
      " (35, 0.08905801283911713),\n",
      " (36, 0.18700710979501922),\n",
      " (37, 0.08444775594941581),\n",
      " (38, 0.06770008835295951),\n",
      " (39, 0.09610431746933021),\n",
      " (40, 0.0820442921557941),\n",
      " (41, 0.040184387881345644),\n",
      " (42, 0.06746441715163996),\n",
      " (43, 0.07952834901719025),\n",
      " (44, 0.3123646925263323),\n",
      " (45, 0.042448906870402335),\n",
      " (46, 0.19769128929296556),\n",
      " (47, 0.06894534489741354),\n",
      " (48, 0.03791738926389524),\n",
      " (49, 0.06294256347807085),\n",
      " (50, 0.059434154043203555),\n",
      " (51, 0.20133144939964195),\n",
      " (52, 0.15284347937954496),\n",
      " (53, 0.09077891257432644),\n",
      " (54, 0.1255309391349747),\n",
      " (55, 0.3550564285544493)]\n"
     ]
    }
   ],
   "source": [
    "model = models.TfidfModel(corpus)\n",
    "corpus_tfidf = model[corpus]\n",
    "    \n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running LDA using Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(corpus, num_topics=10, id2word=dct, passes=2, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.195*\"\n",
      "\" + 0.008*\"trump\" + 0.005*\"immigr\" + 0.004*\"american\" + 0.004*\"peopl\" + 0.004*\"year\" + 0.003*\"go\" + 0.003*\"new\" + 0.003*\"one\" + 0.003*\"presid\"\n",
      "Topic: 1 Word: 0.007*\"trump\" + 0.007*\"peopl\" + 0.007*\"presid\" + 0.005*\"would\" + 0.005*\"attack\" + 0.005*\"report\" + 0.004*\"one\" + 0.004*\"year\" + 0.004*\"state\" + 0.004*\"think\"\n",
      "Topic: 2 Word: 0.007*\"presid\" + 0.007*\"trump\" + 0.006*\"peopl\" + 0.006*\"american\" + 0.006*\"state\" + 0.005*\"would\" + 0.004*\"obama\" + 0.004*\"also\" + 0.004*\"percent\" + 0.004*\"democrat\"\n",
      "Topic: 3 Word: 0.015*\"trump\" + 0.008*\"clinton\" + 0.004*\"presid\" + 0.004*\"news\" + 0.004*\"u\" + 0.004*\"state\" + 0.004*\"time\" + 0.004*\"report\" + 0.003*\"campaign\" + 0.003*\"democrat\"\n",
      "Topic: 4 Word: 0.007*\"trump\" + 0.007*\"presid\" + 0.005*\"would\" + 0.005*\"peopl\" + 0.004*\"state\" + 0.004*\"time\" + 0.004*\"also\" + 0.004*\"new\" + 0.004*\"report\" + 0.003*\"one\"\n",
      "Topic: 5 Word: 0.017*\"trump\" + 0.007*\"presid\" + 0.007*\"clinton\" + 0.005*\"twitter\" + 0.005*\"go\" + 0.005*\"donald\" + 0.005*\"peopl\" + 0.004*\"one\" + 0.004*\"news\" + 0.004*\"state\"\n",
      "Topic: 6 Word: 0.009*\"trump\" + 0.008*\"state\" + 0.005*\"report\" + 0.005*\"year\" + 0.004*\"percent\" + 0.004*\"new\" + 0.004*\"peopl\" + 0.004*\"one\" + 0.003*\"also\" + 0.003*\"refug\"\n",
      "Topic: 7 Word: 0.007*\"report\" + 0.006*\"state\" + 0.006*\"twitter\" + 0.006*\"trump\" + 0.005*\"news\" + 0.004*\"one\" + 0.004*\"breitbart\" + 0.004*\"peopl\" + 0.004*\"would\" + 0.004*\"time\"\n",
      "Topic: 8 Word: 0.009*\"trump\" + 0.005*\"state\" + 0.005*\"peopl\" + 0.005*\"report\" + 0.004*\"one\" + 0.004*\"go\" + 0.004*\"news\" + 0.004*\"new\" + 0.003*\"also\" + 0.003*\"time\"\n",
      "Topic: 9 Word: 0.005*\"trump\" + 0.005*\"texa\" + 0.005*\"would\" + 0.005*\"one\" + 0.004*\"breitbart\" + 0.004*\"state\" + 0.004*\"report\" + 0.003*\"also\" + 0.003*\"immigr\" + 0.003*\"use\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running LDA using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dct, passes=2, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.001*\"trump\" + 0.001*\"abort\" + 0.001*\"presid\" + 0.001*\"parenthood\" + 0.001*\"court\" + 0.001*\"state\" + 0.001*\"student\" + 0.001*\"report\" + 0.001*\"twitter\" + 0.001*\"peopl\"\n",
      "Topic: 1 Word: 0.002*\"trump\" + 0.001*\"polic\" + 0.001*\"migrant\" + 0.001*\"report\" + 0.001*\"peopl\" + 0.001*\"clinton\" + 0.001*\"presid\" + 0.001*\"twitter\" + 0.001*\"new\" + 0.001*\"news\"\n",
      "Topic: 2 Word: 0.005*\"trump\" + 0.003*\"clinton\" + 0.002*\"presid\" + 0.002*\"state\" + 0.002*\"peopl\" + 0.002*\"republican\" + 0.002*\"would\" + 0.002*\"go\" + 0.002*\"donald\" + 0.002*\"cruz\"\n",
      "Topic: 3 Word: 0.833*\"\n",
      "\" + 0.000*\"trump\" + 0.000*\"presid\" + 0.000*\"state\" + 0.000*\"news\" + 0.000*\"clinton\" + 0.000*\"report\" + 0.000*\"twitter\" + 0.000*\"obama\" + 0.000*\"peopl\"\n",
      "Topic: 4 Word: 0.001*\"trump\" + 0.001*\"polic\" + 0.001*\"report\" + 0.001*\"clinton\" + 0.001*\"attack\" + 0.001*\"presid\" + 0.001*\"state\" + 0.001*\"twitter\" + 0.001*\"news\" + 0.001*\"follow\"\n",
      "Topic: 5 Word: 0.003*\"trump\" + 0.002*\"percent\" + 0.002*\"state\" + 0.002*\"presid\" + 0.001*\"immigr\" + 0.001*\"peopl\" + 0.001*\"report\" + 0.001*\"american\" + 0.001*\"clinton\" + 0.001*\"news\"\n",
      "Topic: 6 Word: 0.002*\"trump\" + 0.002*\"\n",
      "\" + 0.001*\"presid\" + 0.001*\"report\" + 0.001*\"clinton\" + 0.001*\"state\" + 0.001*\"peopl\" + 0.001*\"twitter\" + 0.001*\"news\" + 0.001*\"donald\"\n",
      "Topic: 7 Word: 0.005*\"trump\" + 0.004*\"clinton\" + 0.002*\"presid\" + 0.002*\"hillari\" + 0.002*\"peopl\" + 0.002*\"donald\" + 0.002*\"twitter\" + 0.002*\"news\" + 0.002*\"state\" + 0.001*\"go\"\n",
      "Topic: 8 Word: 0.002*\"breitbart\" + 0.002*\"texa\" + 0.002*\"cartel\" + 0.002*\"polic\" + 0.002*\"report\" + 0.002*\"news\" + 0.002*\"gun\" + 0.001*\"trump\" + 0.001*\"border\" + 0.001*\"state\"\n",
      "Topic: 9 Word: 0.001*\"adverti\n",
      "\" + 0.001*\"trump\" + 0.001*\"attack\" + 0.001*\"islam\" + 0.001*\"state\" + 0.001*\"presid\" + 0.001*\"report\" + 0.001*\"peopl\" + 0.001*\"polic\" + 0.001*\"news\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_tfidf.save(\"./LDAmodel/conserv_10.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_topics 10,15,20,25,30\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
