{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling using LDA\n",
    "\n",
    "reference : https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora, models\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "f = open(\"final_liberal.txt\", 'r', encoding = \"UTF8\")\n",
    "# 데이터 받아옴\n",
    "dataset = []\n",
    "while True:\n",
    "    line = f.readline()\n",
    "    if not line: break\n",
    "    dataset += [line.split(' ')]\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dictionary size : 91916\n"
     ]
    }
   ],
   "source": [
    "dct = gensim.corpora.Dictionary(dataset)\n",
    "print('dictionary size : %d' % len(dct))\n",
    "\n",
    "corpus = [dct.doc2bow(line) for line in dataset]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.02318583671783724),\n",
      " (1, 0.05648719313462274),\n",
      " (2, 0.02167849663527989),\n",
      " (3, 0.016896199064181532),\n",
      " (4, 0.008987126420023174),\n",
      " (5, 0.018268130118038125),\n",
      " (6, 0.022830422213800584),\n",
      " (7, 0.015233300031683359),\n",
      " (8, 0.03051709098212779),\n",
      " (9, 0.03673652891591564),\n",
      " (10, 0.019808628152610853),\n",
      " (11, 0.10676754191956293),\n",
      " (12, 0.027321884090074005),\n",
      " (13, 0.02303668801288404),\n",
      " (14, 0.33061462869624125),\n",
      " (15, 0.14536871301084828),\n",
      " (16, 0.011175618059595143),\n",
      " (17, 0.005497550977236616),\n",
      " (18, 0.02152037095545037),\n",
      " (19, 0.05414127938027999),\n",
      " (20, 0.020830343898925626),\n",
      " (21, 0.026286874563610715),\n",
      " (22, 0.05648719313462274),\n",
      " (23, 0.021271201189881017),\n",
      " (24, 0.10597988100564937),\n",
      " (25, 0.015255385767333915),\n",
      " (26, 0.012833492384166464),\n",
      " (27, 0.02829539777969618),\n",
      " (28, 0.026575170747956622),\n",
      " (29, 0.025101848775484117),\n",
      " (30, 0.014265544219830445),\n",
      " (31, 0.033114593343003276),\n",
      " (32, 0.01780172327429373),\n",
      " (33, 0.023533215160429943),\n",
      " (34, 0.02303668801288404),\n",
      " (35, 0.021326702726214848),\n",
      " (36, 0.01211718490970363),\n",
      " (37, 0.020332870195062375),\n",
      " (38, 0.013961124597160295),\n",
      " (39, 0.05928925062394112),\n",
      " (40, 0.03699772924410215),\n",
      " (41, 0.033985770875705985),\n",
      " (42, 0.0293442225245499),\n",
      " (43, 0.03371005600210864),\n",
      " (44, 0.014361851979633937),\n",
      " (45, 0.02611840886492346),\n",
      " (46, 0.02806937411941988),\n",
      " (47, 0.02650509632833091),\n",
      " (48, 0.021269439657735242),\n",
      " (49, 0.014803054338534129),\n",
      " (50, 0.018326226945352388),\n",
      " (51, 0.013474754502338551),\n",
      " (52, 0.01730698697474851),\n",
      " (53, 0.014245848857769495),\n",
      " (54, 0.023355372888006216),\n",
      " (55, 0.023666126896151243),\n",
      " (56, 0.01882305834879099),\n",
      " (57, 0.012396161532710755),\n",
      " (58, 0.022844286258640316),\n",
      " (59, 0.011626303401224182),\n",
      " (60, 0.028013781107421757),\n",
      " (61, 0.005594249015509844),\n",
      " (62, 0.049402936636927915),\n",
      " (63, 0.020698956355844754),\n",
      " (64, 0.012943960259093123),\n",
      " (65, 0.02636663156273936),\n",
      " (66, 0.01934987941513687),\n",
      " (67, 0.017243114081772207),\n",
      " (68, 0.024846847682098907),\n",
      " (69, 0.020528509704451577),\n",
      " (70, 0.07109903137230542),\n",
      " (71, 0.007973283404515301),\n",
      " (72, 0.022298692080744396),\n",
      " (73, 0.013740980658671624),\n",
      " (74, 0.042086496354575696),\n",
      " (75, 0.009234403546025326),\n",
      " (76, 0.03398234310340431),\n",
      " (77, 0.05309764147599611),\n",
      " (78, 0.03429212721512628),\n",
      " (79, 0.027107208283044085),\n",
      " (80, 0.045969960385658405),\n",
      " (81, 0.031541015135850496),\n",
      " (82, 0.03631897729908914),\n",
      " (83, 0.03927391615821453),\n",
      " (84, 0.015742763184692362),\n",
      " (85, 0.07943384712222877),\n",
      " (86, 0.03769183052280068),\n",
      " (87, 0.013500495008361296),\n",
      " (88, 0.019498380719032864),\n",
      " (89, 0.017592126153433838),\n",
      " (90, 0.03590305980768721),\n",
      " (91, 0.018435459988459867),\n",
      " (92, 0.045515522856726415),\n",
      " (93, 0.02458489312806758),\n",
      " (94, 0.022708365571260866),\n",
      " (95, 0.014595715963758322),\n",
      " (96, 0.03969246047944187),\n",
      " (97, 0.023201687567603893),\n",
      " (98, 0.033089612760377314),\n",
      " (99, 0.008515820335489107),\n",
      " (100, 0.03691962205698246),\n",
      " (101, 0.06699649392143173),\n",
      " (102, 0.03963901891382119),\n",
      " (103, 0.01028046361199716),\n",
      " (104, 0.013500495008361296),\n",
      " (105, 0.021193675145405273),\n",
      " (106, 0.04218735882220099),\n",
      " (107, 0.09401061274780646),\n",
      " (108, 0.02797232008963272),\n",
      " (109, 0.022341667033959338),\n",
      " (110, 0.011478202403213355),\n",
      " (111, 0.012707942861539579),\n",
      " (112, 0.03684221539218546),\n",
      " (113, 0.04140655551428261),\n",
      " (114, 0.011288595849286992),\n",
      " (115, 0.02275343504846481),\n",
      " (116, 0.017323029331174005),\n",
      " (117, 0.05054314943758487),\n",
      " (118, 0.03516649652227034),\n",
      " (119, 0.0560710420166184),\n",
      " (120, 0.04024590551274407),\n",
      " (121, 0.013243977874292477),\n",
      " (122, 0.09257131522302606),\n",
      " (123, 0.04581077883687317),\n",
      " (124, 0.012655634205511534),\n",
      " (125, 0.014785086007397325),\n",
      " (126, 0.017738307961280855),\n",
      " (127, 0.012125973897501882),\n",
      " (128, 0.014499671838606933),\n",
      " (129, 0.011977764851928512),\n",
      " (130, 0.024828653666665805),\n",
      " (131, 0.024906352642199044),\n",
      " (132, 0.028454295385702287),\n",
      " (133, 0.035300604209901075),\n",
      " (134, 0.023162114892719455),\n",
      " (135, 0.018794447984673435),\n",
      " (136, 0.02010890858119136),\n",
      " (137, 0.014997080864869849),\n",
      " (138, 0.04452238417995629),\n",
      " (139, 0.010792392528626644),\n",
      " (140, 0.013518559149177255),\n",
      " (141, 0.004748051085698393),\n",
      " (142, 0.041212597120973964),\n",
      " (143, 0.03617512754797145),\n",
      " (144, 0.014767155006615249),\n",
      " (145, 0.16615330315156124),\n",
      " (146, 0.045104455392973926),\n",
      " (147, 0.11835252397567367),\n",
      " (148, 0.013562587256546455),\n",
      " (149, 0.046881120270618394),\n",
      " (150, 0.04127676682380198),\n",
      " (151, 0.019927229191892316),\n",
      " (152, 0.010043289999617332),\n",
      " (153, 0.01887095406145146),\n",
      " (154, 0.008777290259760531),\n",
      " (155, 0.02697054956504093),\n",
      " (156, 0.024829377458415798),\n",
      " (157, 0.01741179929370678),\n",
      " (158, 0.02419926747778525),\n",
      " (159, 0.009100954145501458),\n",
      " (160, 0.023882213741234316),\n",
      " (161, 0.04865426309750105),\n",
      " (162, 0.02288897377365123),\n",
      " (163, 0.03684221539218546),\n",
      " (164, 0.04194615529051982),\n",
      " (165, 0.030318459939405996),\n",
      " (166, 0.027621097266789286),\n",
      " (167, 0.012448490165729506),\n",
      " (168, 0.07406708367331295),\n",
      " (169, 0.025291763699394815),\n",
      " (170, 0.018068898220885893),\n",
      " (171, 0.023386095940221074),\n",
      " (172, 0.027876345316857155),\n",
      " (173, 0.021442219656403534),\n",
      " (174, 0.028995776532033505),\n",
      " (175, 0.0062854242460784705),\n",
      " (176, 0.025201282885342874),\n",
      " (177, 0.05391096424518627),\n",
      " (178, 0.01611502883781368),\n",
      " (179, 0.019560584846110386),\n",
      " (180, 0.06918834377779128),\n",
      " (181, 0.013980180115673518),\n",
      " (182, 0.04572863949379959),\n",
      " (183, 0.02207303778228664),\n",
      " (184, 0.020231064208038177),\n",
      " (185, 0.1724150371547882),\n",
      " (186, 0.024263981679793),\n",
      " (187, 0.027917346749179374),\n",
      " (188, 0.10841860989130474),\n",
      " (189, 0.44972320888415385),\n",
      " (190, 0.00874751349994333),\n",
      " (191, 0.06191335641715046),\n",
      " (192, 0.08354897043403245),\n",
      " (193, 0.04628565761151303),\n",
      " (194, 0.06226765422534433),\n",
      " (195, 0.03003713916393058),\n",
      " (196, 0.028425186470176812),\n",
      " (197, 0.026705137116181634),\n",
      " (198, 0.14209115862617014),\n",
      " (199, 0.01721135402653243),\n",
      " (200, 0.005684450847852771),\n",
      " (201, 0.038258224395306455),\n",
      " (202, 0.010323172739670962),\n",
      " (203, 0.03845041596007466),\n",
      " (204, 0.02739894518480141),\n",
      " (205, 0.03458373553620362),\n",
      " (206, 0.028338444179513353),\n",
      " (207, 0.018737510217281567),\n",
      " (208, 0.010415510277319637),\n",
      " (209, 0.011923909783439044),\n",
      " (210, 0.00860015145550634),\n",
      " (211, 0.054016005524770414),\n",
      " (212, 0.03318997185944832),\n",
      " (213, 0.0286013310588704),\n",
      " (214, 0.006600629999415359),\n",
      " (215, 0.003767097369671592),\n",
      " (216, 0.014554583039804895),\n",
      " (217, 0.050137465763980045),\n",
      " (218, 0.024472837806246435),\n",
      " (219, 0.013911031242119697),\n",
      " (220, 0.013714513955097606),\n",
      " (221, 0.011276633567022703),\n",
      " (222, 0.01817458262636771),\n",
      " (223, 0.007881379404506192),\n",
      " (224, 0.01908491124441867),\n",
      " (225, 0.010507081953702618),\n",
      " (226, 0.04466897933067222),\n",
      " (227, 0.00584328155360993),\n",
      " (228, 0.030881178308006886),\n",
      " (229, 0.021530725050287677),\n",
      " (230, 0.06488219724507463),\n",
      " (231, 0.006336978239452335),\n",
      " (232, 0.023443011357879802),\n",
      " (233, 0.025769642816586957),\n",
      " (234, 0.09061508412693124),\n",
      " (235, 0.032257945112497),\n",
      " (236, 0.03365661443648797),\n",
      " (237, 0.039172376336781535),\n",
      " (238, 0.03145802617652344),\n",
      " (239, 0.07832188163740442),\n",
      " (240, 0.010033727960189925),\n",
      " (241, 0.2580472727072306),\n",
      " (242, 0.030501322399831658),\n",
      " (243, 0.023329553391802305),\n",
      " (244, 0.009599742816255806),\n",
      " (245, 0.031773963413163415),\n",
      " (246, 0.004010315231297588),\n",
      " (247, 0.011678327580876998),\n",
      " (248, 0.01699997729174758),\n",
      " (249, 0.018277092512687765),\n",
      " (250, 0.014339094457491293),\n",
      " (251, 0.045004676417262045),\n",
      " (252, 0.025909633669225544),\n",
      " (253, 0.04187683134133257),\n",
      " (254, 0.006683311027641602),\n",
      " (255, 0.040478294377930255),\n",
      " (256, 0.022392076436255005),\n",
      " (257, 0.014257097846357081),\n",
      " (258, 0.06821515717263694),\n",
      " (259, 0.008968808510199638),\n",
      " (260, 0.11844195431414727),\n",
      " (261, 0.008566611147813737),\n",
      " (262, 0.028224127471554436),\n",
      " (263, 0.011732767454986128),\n",
      " (264, 0.01997454980460414),\n",
      " (265, 0.008291594389970413),\n",
      " (266, 0.012252199305894046),\n",
      " (267, 0.010591321137721137),\n",
      " (268, 0.027232840563489156),\n",
      " (269, 0.06010246323734736),\n",
      " (270, 0.04230138177642236),\n",
      " (271, 0.0544910099217564),\n",
      " (272, 0.04997872978766614),\n",
      " (273, 0.013985632285957193),\n",
      " (274, 0.020080572050143426),\n",
      " (275, 0.0332915116808813),\n",
      " (276, 0.020231064208038177),\n",
      " (277, 0.0459184237236356),\n",
      " (278, 0.030501322399831658),\n",
      " (279, 0.045004676417262045),\n",
      " (280, 0.033273044208407904),\n",
      " (281, 0.03594628940840357),\n",
      " (282, 0.015264868410959906),\n",
      " (283, 0.03194649123111081),\n",
      " (284, 0.027297400228422773),\n",
      " (285, 0.008432305245112187),\n",
      " (286, 0.021585904947393517),\n",
      " (287, 0.03579147393025885),\n",
      " (288, 0.027700889378458122),\n",
      " (289, 0.016028216747308956),\n",
      " (290, 0.03672739172159771),\n",
      " (291, 0.024756630102620948),\n",
      " (292, 0.040419104340368744),\n",
      " (293, 0.01849503028522537),\n",
      " (294, 0.01638803186750452),\n",
      " (295, 0.017776301207984093),\n",
      " (296, 0.030104892070178076),\n",
      " (297, 0.017440236832686244),\n",
      " (298, 0.011566345614785091),\n",
      " (299, 0.01944688423408682),\n",
      " (300, 0.033164772468489825),\n",
      " (301, 0.03039114066594326),\n",
      " (302, 0.05769344844846604),\n",
      " (303, 0.028645934699600237),\n",
      " (304, 0.08102400828715561),\n",
      " (305, 0.02077252423874246),\n",
      " (306, 0.05909611443160324),\n",
      " (307, 0.045621423391154416),\n",
      " (308, 0.014519955714622442),\n",
      " (309, 0.026275540635163772),\n",
      " (310, 0.021785546507143923),\n",
      " (311, 0.0059789086385279334),\n",
      " (312, 0.03516649652227034),\n",
      " (313, 0.17174832998356887),\n",
      " (314, 0.004315828927377277),\n",
      " (315, 0.017600413033832397),\n",
      " (316, 0.0394259532387488),\n",
      " (317, 0.015797747581742492),\n",
      " (318, 0.04140655551428261),\n",
      " (319, 0.027119689536516493),\n",
      " (320, 0.022298692080744396),\n",
      " (321, 0.01028046361199716),\n",
      " (322, 0.1611766090459216),\n",
      " (323, 0.010492515224047245),\n",
      " (324, 0.05142954861512504),\n",
      " (325, 0.025413899491404532),\n",
      " (326, 0.027647094095575444),\n",
      " (327, 0.01227900994698878),\n",
      " (328, 0.014192615473567908),\n",
      " (329, 0.014098167572810204),\n",
      " (330, 0.0354569054795711),\n",
      " (331, 0.019144195635080026),\n",
      " (332, 0.045119622765626435),\n",
      " (333, 0.00927298129000069),\n",
      " (334, 0.025548193294220527),\n",
      " (335, 0.01486623973167343),\n",
      " (336, 0.0347507477712393),\n",
      " (337, 0.016129000164655842),\n",
      " (338, 0.013866473018883151),\n",
      " (339, 0.04747790386961399),\n",
      " (340, 0.04779046425741256),\n",
      " (341, 0.03046443864595432),\n",
      " (342, 0.016559016135103518),\n",
      " (343, 0.02486777923599427),\n",
      " (344, 0.02161117601877897),\n",
      " (345, 0.03188769904251466),\n",
      " (346, 0.013426058034574247),\n",
      " (347, 0.026424055495611234),\n",
      " (348, 0.02404218435644363),\n",
      " (349, 0.010815072816212083),\n",
      " (350, 0.041672139092699886),\n",
      " (351, 0.022050619919909017),\n",
      " (352, 0.029826143217686674),\n",
      " (353, 0.030594227336434954),\n",
      " (354, 0.032441098622537315),\n",
      " (355, 0.020382026794484996),\n",
      " (356, 0.007051447953988415),\n",
      " (357, 0.017031640670978215),\n",
      " (358, 0.03885274273158517),\n",
      " (359, 0.0030116011944776424),\n",
      " (360, 0.029640164154921194),\n",
      " (361, 0.034872337171918004),\n",
      " (362, 0.03790707323089632),\n",
      " (363, 0.018991869253908777),\n",
      " (364, 0.022760969562493762),\n",
      " (365, 0.015509201996123073),\n",
      " (366, 0.014761186275207214),\n",
      " (367, 0.05551885205252567),\n",
      " (368, 0.04197737648378013),\n",
      " (369, 0.08726826207160625),\n",
      " (370, 0.009277721309491204),\n",
      " (371, 0.018620082755902042),\n",
      " (372, 0.11272649821153663),\n",
      " (373, 0.016827700408819833),\n",
      " (374, 0.030033707175552336),\n",
      " (375, 0.030575566171820008),\n",
      " (376, 0.022874783764832787),\n",
      " (377, 0.07239973028538305),\n",
      " (378, 0.03385363658033146),\n",
      " (379, 0.03384512582092409),\n",
      " (380, 0.051711043971132825),\n",
      " (381, 0.08457661673463882),\n",
      " (382, 0.03603363609600691),\n",
      " (383, 0.03470319467887876),\n",
      " (384, 0.01960230473530754),\n",
      " (385, 0.029540385179209313),\n",
      " (386, 0.012929470968719733),\n",
      " (387, 0.023241442521689148),\n",
      " (388, 0.025911950228795357),\n",
      " (389, 0.013904209179501565),\n",
      " (390, 0.013038738242531673),\n",
      " (391, 0.020851710327444345),\n",
      " (392, 0.015778898661094356),\n",
      " (393, 0.007450045311418987),\n",
      " (394, 0.019269028376373638),\n",
      " (395, 0.02429994333712109),\n",
      " (396, 0.01976590140558801),\n",
      " (397, 0.03001621824297837),\n",
      " (398, 0.013936686302572719),\n",
      " (399, 0.005134340330296927),\n",
      " (400, 0.008257825379409646),\n",
      " (401, 0.009369588361942922),\n",
      " (402, 0.03328046056536155),\n",
      " (403, 0.006634942817288409),\n",
      " (404, 0.010499795515724851)]\n"
     ]
    }
   ],
   "source": [
    "model = models.TfidfModel(corpus)\n",
    "corpus_tfidf = model[corpus]\n",
    "    \n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running LDA using Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(corpus, num_topics=10, id2word=dct, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.007*\"like\" + 0.007*\"peopl\" + 0.007*\"one\" + 0.006*\"said\" + 0.006*\"would\" + 0.005*\"time\" + 0.004*\"work\" + 0.004*\"get\" + 0.004*\"year\" + 0.004*\"want\"\n",
      "Topic: 1 Word: 0.020*\"trump\" + 0.006*\"said\" + 0.006*\"clinton\" + 0.005*\"one\" + 0.005*\"peopl\" + 0.005*\"presid\" + 0.005*\"polit\" + 0.005*\"would\" + 0.005*\"campaign\" + 0.005*\"elect\"\n",
      "Topic: 2 Word: 0.010*\"said\" + 0.006*\"trump\" + 0.006*\"court\" + 0.006*\"would\" + 0.006*\"state\" + 0.005*\"one\" + 0.004*\"presid\" + 0.004*\"year\" + 0.004*\"new\" + 0.004*\"time\"\n",
      "Topic: 3 Word: 0.007*\"one\" + 0.006*\"peopl\" + 0.006*\"like\" + 0.005*\"year\" + 0.005*\"said\" + 0.005*\"also\" + 0.004*\"time\" + 0.004*\"new\" + 0.004*\"say\" + 0.003*\"would\"\n",
      "Topic: 4 Word: 0.009*\"trump\" + 0.005*\"like\" + 0.005*\"would\" + 0.005*\"peopl\" + 0.004*\"one\" + 0.004*\"said\" + 0.004*\"clinton\" + 0.004*\"presid\" + 0.004*\"state\" + 0.004*\"us\"\n",
      "Topic: 5 Word: 0.011*\"trump\" + 0.006*\"one\" + 0.005*\"like\" + 0.004*\"presid\" + 0.004*\"new\" + 0.004*\"said\" + 0.004*\"show\" + 0.003*\"make\" + 0.003*\"polit\" + 0.003*\"time\"\n",
      "Topic: 6 Word: 0.011*\"trump\" + 0.006*\"like\" + 0.006*\"compani\" + 0.005*\"one\" + 0.005*\"new\" + 0.005*\"said\" + 0.005*\"year\" + 0.005*\"would\" + 0.004*\"busi\" + 0.003*\"presid\"\n",
      "Topic: 7 Word: 0.006*\"said\" + 0.006*\"like\" + 0.005*\"one\" + 0.004*\"peopl\" + 0.004*\"year\" + 0.004*\"say\" + 0.004*\"also\" + 0.003*\"new\" + 0.003*\"trump\" + 0.003*\"time\"\n",
      "Topic: 8 Word: 0.009*\"would\" + 0.008*\"trump\" + 0.008*\"republican\" + 0.007*\"health\" + 0.006*\"peopl\" + 0.006*\"like\" + 0.006*\"plan\" + 0.005*\"care\" + 0.005*\"insur\" + 0.005*\"tax\"\n",
      "Topic: 9 Word: 0.008*\"peopl\" + 0.006*\"said\" + 0.005*\"one\" + 0.005*\"state\" + 0.004*\"would\" + 0.004*\"like\" + 0.004*\"polic\" + 0.004*\"american\" + 0.003*\"year\" + 0.003*\"law\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running LDA using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dct, passes=2, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.001*\"trump\" + 0.001*\"de\" + 0.001*\"le\" + 0.001*\"sponsor\n",
      "\" + 0.001*\"song\" + 0.001*\"clinton\" + 0.001*\"film\" + 0.001*\"women\" + 0.001*\"sander\" + 0.001*\"la\"\n",
      "Topic: 1 Word: 0.004*\"trump\" + 0.002*\"clinton\" + 0.002*\"republican\" + 0.001*\"democrat\" + 0.001*\"sander\" + 0.001*\"presid\" + 0.001*\"vote\" + 0.001*\"women\" + 0.001*\"obama\" + 0.001*\"campaign\"\n",
      "Topic: 2 Word: 0.001*\"trump\" + 0.001*\"drug\" + 0.001*\"marijuana\" + 0.001*\"opioid\" + 0.001*\"clinton\" + 0.001*\"women\" + 0.001*\"court\" + 0.001*\"obama\" + 0.001*\"presid\" + 0.001*\"appl\"\n",
      "Topic: 3 Word: 0.001*\"trump\" + 0.001*\"student\" + 0.001*\"school\" + 0.001*\"uber\" + 0.000*\"women\" + 0.000*\"compani\" + 0.000*\"said\" + 0.000*\"presid\" + 0.000*\"u\" + 0.000*\"citi\"\n",
      "Topic: 4 Word: 0.001*\"\n",
      "\" + 0.001*\"trump\" + 0.001*\"uber\" + 0.001*\"polic\" + 0.001*\"song\" + 0.000*\"waymo\" + 0.000*\"women\" + 0.000*\"offic\" + 0.000*\"black\" + 0.000*\"said\"\n",
      "Topic: 5 Word: 0.001*\"trump\" + 0.001*\"student\" + 0.001*\"polic\" + 0.001*\"court\" + 0.001*\"u\" + 0.001*\"clinton\" + 0.001*\"state\" + 0.000*\"law\" + 0.000*\"presid\" + 0.000*\"republican\"\n",
      "Topic: 6 Word: 0.001*\"bundi\" + 0.001*\"trump\" + 0.000*\"u\" + 0.000*\"compani\" + 0.000*\"pleas\" + 0.000*\"state\" + 0.000*\"said\" + 0.000*\"ad\" + 0.000*\"student\" + 0.000*\"black\"\n",
      "Topic: 7 Word: 0.002*\"trump\" + 0.001*\"tax\" + 0.001*\"health\" + 0.001*\"insur\" + 0.001*\"student\" + 0.001*\"compani\" + 0.001*\"zika\" + 0.001*\"percent\" + 0.001*\"school\" + 0.001*\"plan\"\n",
      "Topic: 8 Word: 0.001*\"trump\" + 0.001*\"polic\" + 0.001*\"locht\" + 0.000*\"school\" + 0.000*\"farc\" + 0.000*\"u\" + 0.000*\"student\" + 0.000*\"clinton\" + 0.000*\"citi\" + 0.000*\"court\"\n",
      "Topic: 9 Word: 0.001*\"trump\" + 0.001*\"polic\" + 0.001*\"student\" + 0.001*\"school\" + 0.000*\"women\" + 0.000*\"republican\" + 0.000*\"attack\" + 0.000*\"said\" + 0.000*\"clinton\" + 0.000*\"palantir\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_tfidf.save(\"ldamodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_topics 10,15,20,25,30\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
