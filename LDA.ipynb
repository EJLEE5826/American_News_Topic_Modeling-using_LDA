{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DnCmd6ODINDW"
   },
   "source": [
    "# Topic modeling using LDA\n",
    "\n",
    "reference : https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S7Ml-73wINDd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmswn\\Anaconda3\\envs\\TF\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim import corpora, models\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "fname = \"saved_conserv.txt\" # dataset name\n",
    "save_name = \"./new_model/conserv_\"  # 저장할 dir. 'conserv_' or 'liberal_' \n",
    "topicN = 20               # topic 개수\n",
    "\n",
    "f = open(fname, 'r', encoding = \"UTF8\")\n",
    "\n",
    "# 데이터 받아옴\n",
    "dataset = []\n",
    "\n",
    "while True:\n",
    "    line = f.readline()\n",
    "    if not line: break\n",
    "    dataset += [line.split()]\n",
    "\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 42744
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1845,
     "status": "ok",
     "timestamp": 1559987426159,
     "user": {
      "displayName": "EJ LEE",
      "photoUrl": "",
      "userId": "07041686333152487261"
     },
     "user_tz": -540
    },
    "id": "NrKfsPfxLmfC",
    "outputId": "d270b3d0-f351-4441-afe0-f642e22e7466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['tuesday',\n",
      "  'broadcast',\n",
      "  'cnn',\n",
      "  'situat',\n",
      "  'room',\n",
      "  'cnn',\n",
      "  'senior',\n",
      "  'washington',\n",
      "  'correspond',\n",
      "  'jeff',\n",
      "  'zeleni',\n",
      "  'state',\n",
      "  'chelsea',\n",
      "  'man',\n",
      "  'transit',\n",
      "  'man',\n",
      "  'woman',\n",
      "  'certainli',\n",
      "  'play',\n",
      "  'obama',\n",
      "  'decis',\n",
      "  'commut',\n",
      "  'man',\n",
      "  'sentenc',\n",
      "  'without',\n",
      "  'hard',\n",
      "  'imagin',\n",
      "  'done',\n",
      "  'zeleni',\n",
      "  'question',\n",
      "  'white',\n",
      "  'answer',\n",
      "  'answer',\n",
      "  'import',\n",
      "  'much',\n",
      "  'person',\n",
      "  'stori',\n",
      "  'chelsea',\n",
      "  'man',\n",
      "  'involv',\n",
      "  'outcri',\n",
      "  'left',\n",
      "  'strong',\n",
      "  'difficult',\n",
      "  'time',\n",
      "  'feder',\n",
      "  'prison',\n",
      "  'question',\n",
      "  'central',\n",
      "  'question',\n",
      "  'without',\n",
      "  'wonder',\n",
      "  'outcom',\n",
      "  'might',\n",
      "  'transit',\n",
      "  'man',\n",
      "  'woman',\n",
      "  'certainli',\n",
      "  'play',\n",
      "  'without',\n",
      "  'hard',\n",
      "  'imagin',\n",
      "  'done',\n",
      "  'mediait'],\n",
      " ['group',\n",
      "  'american',\n",
      "  'spring',\n",
      "  'break',\n",
      "  'revel',\n",
      "  'reportedli',\n",
      "  'chant',\n",
      "  'build',\n",
      "  'wall',\n",
      "  'famili',\n",
      "  'cruis',\n",
      "  'cancun',\n",
      "  'sf',\n",
      "  'gate',\n",
      "  'mail',\n",
      "  'group',\n",
      "  'aboard',\n",
      "  'captain',\n",
      "  'hook',\n",
      "  'pirat',\n",
      "  'ship',\n",
      "  'dinner',\n",
      "  'cruis',\n",
      "  'revel',\n",
      "  'broke',\n",
      "  'chant',\n",
      "  'shock',\n",
      "  'tourist',\n",
      "  'board',\n",
      "  'anaximandro',\n",
      "  'amabl',\n",
      "  'burga',\n",
      "  'peruvian',\n",
      "  'tourist',\n",
      "  'board',\n",
      "  'mexican',\n",
      "  'wife',\n",
      "  'suli',\n",
      "  'wit',\n",
      "  'scene',\n",
      "  'today',\n",
      "  'suli',\n",
      "  'wife',\n",
      "  'nativ',\n",
      "  'mexico',\n",
      "  'watch',\n",
      "  'entertain',\n",
      "  'coast',\n",
      "  'cancun',\n",
      "  'aboard',\n",
      "  'boat',\n",
      "  'end',\n",
      "  'flock',\n",
      "  'american',\n",
      "  'mayb',\n",
      "  'influenc',\n",
      "  'alcohol',\n",
      "  'mayb',\n",
      "  'began',\n",
      "  'sing',\n",
      "  'infam',\n",
      "  'build',\n",
      "  'wall',\n",
      "  'chant',\n",
      "  'louder',\n",
      "  'louder',\n",
      "  'wrote',\n",
      "  'mexican',\n",
      "  'tourist',\n",
      "  'aboard',\n",
      "  'ship',\n",
      "  'reportedli',\n",
      "  'complain',\n",
      "  'chant',\n",
      "  'spring',\n",
      "  'breaker',\n",
      "  'stop',\n",
      "  'yucatan',\n",
      "  'time',\n",
      "  'denounc',\n",
      "  'chant',\n",
      "  'editori',\n",
      "  'friday',\n",
      "  'act',\n",
      "  'xenophobia',\n",
      "  'discrimin',\n",
      "  'mexican',\n",
      "  'within',\n",
      "  'countri',\n",
      "  'paper',\n",
      "  'racist',\n",
      "  'hymn',\n",
      "  'far',\n",
      "  'isol',\n",
      "  'incid',\n",
      "  'drawn',\n",
      "  'ire',\n",
      "  'tourism',\n",
      "  'sector',\n",
      "  'worker',\n",
      "  'spring',\n",
      "  'breaker',\n",
      "  'action',\n",
      "  'offens',\n",
      "  'rude',\n",
      "  'toward',\n",
      "  'mexican',\n",
      "  'time',\n",
      "  'chant',\n",
      "  'build',\n",
      "  'wall',\n",
      "  'racist',\n",
      "  'other',\n",
      "  'cnn',\n",
      "  'call',\n",
      "  'video',\n",
      "  'children',\n",
      "  'chant',\n",
      "  'build',\n",
      "  'wall',\n",
      "  'michigan',\n",
      "  'middl',\n",
      "  'school',\n",
      "  'went',\n",
      "  'viral',\n",
      "  'decemb',\n",
      "  'exampl',\n",
      "  'racism',\n",
      "  'photo',\n",
      "  'file'],\n",
      " ['honour',\n",
      "  'crime',\n",
      "  'risen',\n",
      "  '40',\n",
      "  'per',\n",
      "  'cent',\n",
      "  'five',\n",
      "  'london',\n",
      "  'number',\n",
      "  'forc',\n",
      "  'marriag',\n",
      "  'doubl',\n",
      "  'period',\n",
      "  'accord',\n",
      "  'figur',\n",
      "  'obtain',\n",
      "  'standard',\n",
      "  'children',\n",
      "  'involv',\n",
      "  'abus',\n",
      "  'younger',\n",
      "  'sinc',\n",
      "  '2012',\n",
      "  'honour',\n",
      "  'crime',\n",
      "  'metropolitan',\n",
      "  'rose',\n",
      "  '1',\n",
      "  '081',\n",
      "  'relat',\n",
      "  'forc',\n",
      "  'marriag',\n",
      "  'shot',\n",
      "  '367',\n",
      "  'women',\n",
      "  'girl',\n",
      "  'victim',\n",
      "  'vast',\n",
      "  'major',\n",
      "  'incid',\n",
      "  'half',\n",
      "  'come',\n",
      "  'asian',\n",
      "  'background',\n",
      "  'paper',\n",
      "  'knive',\n",
      "  'gun',\n",
      "  'involv',\n",
      "  '70',\n",
      "  'incid',\n",
      "  'dozen',\n",
      "  'rape',\n",
      "  'sexual',\n",
      "  'crime',\n",
      "  'detect',\n",
      "  'chief',\n",
      "  'inspector',\n",
      "  'sam',\n",
      "  'faulkner',\n",
      "  'met',\n",
      "  'commun',\n",
      "  'safeti',\n",
      "  'unit',\n",
      "  'crime',\n",
      "  'stem',\n",
      "  'commun',\n",
      "  'use',\n",
      "  'cultur',\n",
      "  'religi',\n",
      "  'justif',\n",
      "  'male',\n",
      "  'violenc',\n",
      "  'women',\n",
      "  'girl',\n",
      "  'often',\n",
      "  'base',\n",
      "  'tradit',\n",
      "  'wherebi',\n",
      "  'individu',\n",
      "  'famili',\n",
      "  'commun',\n",
      "  'honour',\n",
      "  'weight',\n",
      "  'women',\n",
      "  'girl',\n",
      "  'includ',\n",
      "  'refus',\n",
      "  'along',\n",
      "  'marriag',\n",
      "  'see',\n",
      "  'increas',\n",
      "  'type',\n",
      "  'offenc',\n",
      "  'posit',\n",
      "  'step',\n",
      "  'indic',\n",
      "  'victim',\n",
      "  'confid',\n",
      "  'offenc',\n",
      "  'seek',\n",
      "  'support',\n",
      "  'need',\n",
      "  'politician',\n",
      "  'today',\n",
      "  'call',\n",
      "  'find',\n",
      "  'troubl',\n",
      "  'shock',\n",
      "  'abhorr',\n",
      "  'labour',\n",
      "  'mp',\n",
      "  'yvett',\n",
      "  'cooper',\n",
      "  'chair',\n",
      "  'common',\n",
      "  'home',\n",
      "  'affair',\n",
      "  'select',\n",
      "  'committe',\n",
      "  'told',\n",
      "  'standard',\n",
      "  'aw',\n",
      "  'crime',\n",
      "  'still',\n",
      "  'hidden',\n",
      "  'honour',\n",
      "  'violenc',\n",
      "  'women',\n",
      "  'rape',\n",
      "  'tortur',\n",
      "  'abus',\n",
      "  'famili',\n",
      "  'member',\n",
      "  'deadli',\n",
      "  'crime',\n",
      "  'still',\n",
      "  'littl',\n",
      "  'protect',\n",
      "  'prosecut',\n",
      "  'much',\n",
      "  'stigma',\n",
      "  'prevent',\n",
      "  'come',\n",
      "  'forward',\n",
      "  'vital',\n",
      "  'victim',\n",
      "  'speak',\n",
      "  'proper',\n",
      "  'help',\n",
      "  'support',\n",
      "  'group',\n",
      "  'keep',\n",
      "  'safe',\n",
      "  'figur',\n",
      "  'obtain',\n",
      "  'use',\n",
      "  'freedom',\n",
      "  'inform',\n",
      "  'request',\n",
      "  'violenc',\n",
      "  'person',\n",
      "  'common',\n",
      "  'honour',\n",
      "  'attack',\n",
      "  'account',\n",
      "  '85',\n",
      "  'per',\n",
      "  'cent',\n",
      "  'incid',\n",
      "  'sexual',\n",
      "  'violenc',\n",
      "  'second',\n",
      "  'largest',\n",
      "  'categori',\n",
      "  '56',\n",
      "  'rape',\n",
      "  '11',\n",
      "  'sexual',\n",
      "  'crime',\n",
      "  '84',\n",
      "  'per',\n",
      "  'cent',\n",
      "  'perpetr',\n",
      "  'women',\n",
      "  'asian',\n",
      "  'women',\n",
      "  'account',\n",
      "  'half'],\n",
      " ['former',\n",
      "  'senior',\n",
      "  'editor',\n",
      "  'announc',\n",
      "  'found',\n",
      "  'new',\n",
      "  '12',\n",
      "  'million',\n",
      "  'dollar',\n",
      "  'media',\n",
      "  'inc',\n",
      "  'post',\n",
      "  'outlin',\n",
      "  'new',\n",
      "  'busi',\n",
      "  'plan',\n",
      "  '12',\n",
      "  'million',\n",
      "  'invest',\n",
      "  'fund',\n",
      "  'receiv',\n",
      "  'undisclos',\n",
      "  'investor',\n",
      "  'reportedli',\n",
      "  'hire',\n",
      "  'season',\n",
      "  'media',\n",
      "  'execut',\n",
      "  'lead',\n",
      "  'new',\n",
      "  'team',\n",
      "  'base',\n",
      "  'miami',\n",
      "  'florida',\n",
      "  'new',\n",
      "  'manag',\n",
      "  'book',\n",
      "  'tour',\n",
      "  'merchandis',\n",
      "  'radio',\n",
      "  'tv',\n",
      "  'statement',\n",
      "  'vaniti',\n",
      "  'namepl',\n",
      "  'person',\n",
      "  'blog',\n",
      "  'fulli',\n",
      "  'talent',\n",
      "  'factori',\n",
      "  'manag',\n",
      "  'dedic',\n",
      "  'destruct',\n",
      "  'correct',\n",
      "  'progress',\n",
      "  'left',\n",
      "  'spend',\n",
      "  'everi',\n",
      "  'wake',\n",
      "  'moment',\n",
      "  'rest',\n",
      "  'life',\n",
      "  'live',\n",
      "  'journalist',\n",
      "  'professor',\n",
      "  'politician',\n",
      "  'feminist',\n",
      "  'black',\n",
      "  'live',\n",
      "  'matter',\n",
      "  'activist',\n",
      "  'profession',\n",
      "  'victim',\n",
      "  'live',\n",
      "  'hell',\n",
      "  'free',\n",
      "  'speech',\n",
      "  'back',\n",
      "  'fabul',\n",
      "  'statement',\n",
      "  'outlin',\n",
      "  'plan',\n",
      "  'free',\n",
      "  'speech',\n",
      "  'week',\n",
      "  'berkeley',\n",
      "  'releas',\n",
      "  'detail',\n",
      "  'free',\n",
      "  'speech',\n",
      "  'week',\n",
      "  'book',\n",
      "  'danger',\n",
      "  'new',\n",
      "  'tour',\n",
      "  'media',\n",
      "  'cinco',\n",
      "  'florida',\n",
      "  'may',\n",
      "  '5',\n",
      "  'occasion',\n",
      "  'updat',\n",
      "  'fan',\n",
      "  'enemi',\n",
      "  'see',\n",
      "  'hear',\n",
      "  'read',\n",
      "  'work',\n",
      "  'clarifi',\n",
      "  'current',\n",
      "  'statu',\n",
      "  'privileg',\n",
      "  'grant',\n",
      "  'chariti',\n",
      "  'privileg',\n",
      "  'grant',\n",
      "  'recent',\n",
      "  'announc',\n",
      "  '10',\n",
      "  'recipi',\n",
      "  'pilot',\n",
      "  'grant',\n",
      "  'program',\n",
      "  'recipi',\n",
      "  'receiv',\n",
      "  '2',\n",
      "  '500',\n",
      "  'toward',\n",
      "  'higher',\n",
      "  'educ',\n",
      "  'second',\n",
      "  'grant',\n",
      "  'occur',\n",
      "  'second',\n",
      "  'half',\n",
      "  '2017',\n",
      "  'visit',\n",
      "  'privilegegr',\n",
      "  'inform',\n",
      "  'inc',\n",
      "  'bring',\n",
      "  'laughter',\n",
      "  'war',\n",
      "  'everi',\n",
      "  'corner',\n",
      "  'america',\n",
      "  'dozen',\n",
      "  'differ',\n",
      "  'format',\n",
      "  'fight',\n",
      "  'harder',\n",
      "  'look',\n",
      "  'hotter',\n",
      "  'anyon',\n",
      "  'els',\n",
      "  'right',\n",
      "  'damag',\n",
      "  'left',\n",
      "  'anyon',\n",
      "  'els',\n",
      "  'american',\n",
      "  'cultur',\n",
      "  'read',\n",
      "  'full',\n",
      "  'post',\n",
      "  'news',\n",
      "  'cover',\n",
      "  'issu',\n",
      "  'free',\n",
      "  'speech',\n",
      "  'onlin',\n",
      "  'censorship',\n",
      "  'com'],\n",
      " ['focu',\n",
      "  'continu',\n",
      "  'media',\n",
      "  'alleg',\n",
      "  'collus',\n",
      "  'russian',\n",
      "  'campaign',\n",
      "  'shift',\n",
      "  'jare',\n",
      "  'kushner',\n",
      "  'husband',\n",
      "  'daughter',\n",
      "  'ivanka',\n",
      "  'top',\n",
      "  'advis',\n",
      "  'kushner',\n",
      "  'discuss',\n",
      "  'russian',\n",
      "  'ambassador',\n",
      "  'sergey',\n",
      "  'kislyak',\n",
      "  'possibl',\n",
      "  'establish',\n",
      "  'direct',\n",
      "  'secur',\n",
      "  'conduit',\n",
      "  'commun',\n",
      "  'moscow',\n",
      "  'transit',\n",
      "  'team',\n",
      "  'establish',\n",
      "  '2016',\n",
      "  'presidenti',\n",
      "  'elect',\n",
      "  'washington',\n",
      "  'post',\n",
      "  'friday',\n",
      "  'made',\n",
      "  'propos',\n",
      "  'meet',\n",
      "  'dec',\n",
      "  '1',\n",
      "  '2',\n",
      "  'tower',\n",
      "  'accord',\n",
      "  'intercept',\n",
      "  'russian',\n",
      "  'commun',\n",
      "  'review',\n",
      "  'offici',\n",
      "  'post',\n",
      "  'kislyak',\n",
      "  'kushner',\n",
      "  'suggest',\n",
      "  'use',\n",
      "  'russian',\n",
      "  'diplomat',\n",
      "  'facil',\n",
      "  'unit',\n",
      "  'state',\n",
      "  'commun',\n",
      "  'michael',\n",
      "  'first',\n",
      "  'nation',\n",
      "  'secur',\n",
      "  'advis',\n",
      "  'attend',\n",
      "  'meet',\n",
      "  'accord',\n",
      "  'post',\n",
      "  'cite',\n",
      "  'sourc',\n",
      "  'except',\n",
      "  'offici',\n",
      "  'familiar',\n",
      "  'matter',\n",
      "  'white',\n",
      "  'acknowledg',\n",
      "  'meet',\n",
      "  'march',\n",
      "  'play',\n",
      "  'signific',\n",
      "  'post',\n",
      "  'fbi',\n",
      "  'consid',\n",
      "  'meet',\n",
      "  'anoth',\n",
      "  'russian',\n",
      "  'banker',\n",
      "  'worthi',\n",
      "  'neither',\n",
      "  'meet',\n",
      "  'commun',\n",
      "  'american',\n",
      "  'involv',\n",
      "  'surveil',\n",
      "  'post',\n",
      "  'offici',\n",
      "  'respond',\n",
      "  'request',\n",
      "  'comment',\n",
      "  'post',\n",
      "  'includ',\n",
      "  'white',\n",
      "  'robert',\n",
      "  'kelner',\n",
      "  'lawyer',\n",
      "  'flynn',\n",
      "  'russian',\n",
      "  'embassi',\n",
      "  'accord',\n",
      "  'newspap',\n",
      "  'russia',\n",
      "  'time',\n",
      "  'feed',\n",
      "  'fals',\n",
      "  'inform',\n",
      "  'commun',\n",
      "  'stream',\n",
      "  'suspect',\n",
      "  'monitor',\n",
      "  'way',\n",
      "  'sow',\n",
      "  'misinform',\n",
      "  'confus',\n",
      "  'among',\n",
      "  'analyst',\n",
      "  'offici',\n",
      "  'unclear',\n",
      "  'kislyak',\n",
      "  'gain',\n",
      "  'fals',\n",
      "  'character',\n",
      "  'contact',\n",
      "  'kushner',\n",
      "  'moscow',\n",
      "  'particularli',\n",
      "  'time',\n",
      "  'kremlin',\n",
      "  'still',\n",
      "  'saw',\n",
      "  'prospect',\n",
      "  'dramat',\n",
      "  'improv',\n",
      "  'relat',\n",
      "  'post',\n",
      "  'add',\n",
      "  'drama',\n",
      "  'kushner',\n",
      "  'angl',\n",
      "  'ongo',\n",
      "  'russian',\n",
      "  'saga',\n",
      "  'current',\n",
      "  'former',\n",
      "  'intellig',\n",
      "  'offici',\n",
      "  'although',\n",
      "  'russian',\n",
      "  'diplomat',\n",
      "  'secur',\n",
      "  'mean',\n",
      "  'commun',\n",
      "  'moscow',\n",
      "  'kushner',\n",
      "  'appar',\n",
      "  'request',\n",
      "  'access',\n",
      "  'channel',\n",
      "  'extraordinari',\n",
      "  'trust',\n",
      "  'russian',\n",
      "  'leak',\n",
      "  'side',\n",
      "  'former',\n",
      "  'senior',\n",
      "  'intellig',\n",
      "  'offici',\n",
      "  'transit',\n",
      "  'member',\n",
      "  'russian',\n",
      "  'embassi',\n",
      "  'caus',\n",
      "  'great',\n",
      "  'deal',\n",
      "  'concern',\n",
      "  'entir',\n",
      "  'idea',\n",
      "  'seem',\n",
      "  'extrem',\n",
      "  'naiv',\n",
      "  'absolut',\n",
      "  'crazi',\n",
      "  'common',\n",
      "  'senior',\n",
      "  'advis',\n",
      "  'newli',\n",
      "  'elect',\n",
      "  'contact',\n",
      "  'foreign',\n",
      "  'leader',\n",
      "  'offici',\n",
      "  'stori',\n",
      "  'state',\n",
      "  'toward',\n",
      "  'end',\n",
      "  'cite',\n",
      "  'intellig',\n",
      "  'belief',\n",
      "  'unpreced',\n",
      "  'campaign',\n",
      "  'russian',\n",
      "  'interfer',\n",
      "  'last',\n",
      "  'presidenti',\n",
      "  'race',\n",
      "  'help',\n",
      "  'elect',\n",
      "  'obama',\n",
      "  'administr',\n",
      "  'offici',\n",
      "  'member',\n",
      "  'transit',\n",
      "  'team',\n",
      "  'never',\n",
      "  'approach',\n",
      "  'arrang',\n",
      "  'secur',\n",
      "  'commun',\n",
      "  'channel',\n",
      "  'russian',\n",
      "  'contact',\n",
      "  'possibl',\n",
      "  'concern',\n",
      "  'leak',\n",
      "  'post',\n",
      "  'state',\n",
      "  'depart',\n",
      "  'white',\n",
      "  'nation',\n",
      "  'secur',\n",
      "  'council',\n",
      "  'intellig',\n",
      "  'agenc',\n",
      "  'abil',\n",
      "  'set',\n",
      "  'secur',\n",
      "  'commun',\n",
      "  'channel',\n",
      "  'foreign',\n",
      "  'leader',\n",
      "  'though',\n",
      "  'transit',\n",
      "  'team',\n",
      "  'unusu',\n",
      "  'addit',\n",
      "  'post',\n",
      "  'first',\n",
      "  'heard',\n",
      "  'kushner',\n",
      "  'meet',\n",
      "  'though',\n",
      "  'anonym',\n",
      "  'letter',\n",
      "  'among',\n",
      "  'thing',\n",
      "  'kushner',\n",
      "  'talk',\n",
      "  'kislyak',\n",
      "  'set',\n",
      "  'commun',\n",
      "  'channel',\n",
      "  'addit',\n",
      "  'discuss',\n",
      "  'set',\n",
      "  'commun',\n",
      "  'channel',\n",
      "  'kushner',\n",
      "  'flynn',\n",
      "  'kislyak',\n",
      "  'talk',\n",
      "  'arrang',\n",
      "  'meet',\n",
      "  'repres',\n",
      "  'russian',\n",
      "  'contact',\n",
      "  'third',\n",
      "  'countri',\n",
      "  'whose',\n",
      "  'name',\n",
      "  'identifi',\n",
      "  'accord',\n",
      "  'anonym',\n",
      "  'letter',\n",
      "  'post']]\n"
     ]
    }
   ],
   "source": [
    "pprint(dataset[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zpGtYxriZyOA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pUBh_90fINEB"
   },
   "source": [
    "## Bag of words on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19172,
     "status": "ok",
     "timestamp": 1559987448659,
     "user": {
      "displayName": "EJ LEE",
      "photoUrl": "",
      "userId": "07041686333152487261"
     },
     "user_tz": -540
    },
    "id": "vGAnAS2TINED",
    "outputId": "a1583067-4488-49dd-d73b-2ba86a63d5a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dictionary size : 55227\n"
     ]
    }
   ],
   "source": [
    "dct = gensim.corpora.Dictionary(dataset)\n",
    "print('dictionary size : %d' % len(dct))\n",
    "\n",
    "corpus = [dct.doc2bow(line) for line in dataset]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pDXQ2OujINEN"
   },
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6926
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2488,
     "status": "ok",
     "timestamp": 1559987451961,
     "user": {
      "displayName": "EJ LEE",
      "photoUrl": "",
      "userId": "07041686333152487261"
     },
     "user_tz": -540
    },
    "id": "R8gQDLmoINEP",
    "outputId": "dcb46753-7f3c-4c3a-a1ac-d86f602fcb0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.1654889451420026),\n",
      " (1, 0.08853617937044052),\n",
      " (2, 0.09578025527090075),\n",
      " (3, 0.19223669438375798),\n",
      " (4, 0.28725830600851043),\n",
      " (5, 0.15497070742817248),\n",
      " (6, 0.17172349117621),\n",
      " (7, 0.11286829052038373),\n",
      " (8, 0.0655807425860439),\n",
      " (9, 0.09764217237242317),\n",
      " (10, 0.13796813645057787),\n",
      " (11, 0.06299359124378018),\n",
      " (12, 0.1517805203512606),\n",
      " (13, 0.21872978431279783),\n",
      " (14, 0.06416105796420278),\n",
      " (15, 0.07274446947974281),\n",
      " (16, 0.10444594712345447),\n",
      " (17, 0.05928583468107513),\n",
      " (18, 0.2983321457985086),\n",
      " (19, 0.1731972460113172),\n",
      " (20, 0.0723453767111886),\n",
      " (21, 0.05195027710630144),\n",
      " (22, 0.04954041914244451),\n",
      " (23, 0.11851106812416558),\n",
      " (24, 0.18250684661075908),\n",
      " (25, 0.052417726437127096),\n",
      " (26, 0.13761311358788283),\n",
      " (27, 0.09746420513179158),\n",
      " (28, 0.17005268795818823),\n",
      " (29, 0.09099652818105437),\n",
      " (30, 0.06446758302897908),\n",
      " (31, 0.10815414807446412),\n",
      " (32, 0.08628679372702354),\n",
      " (33, 0.022196764226817163),\n",
      " (34, 0.06183992576521185),\n",
      " (35, 0.08244153383854216),\n",
      " (36, 0.025667379725359492),\n",
      " (37, 0.2273568630109433),\n",
      " (38, 0.06622582606394059),\n",
      " (39, 0.05725340360570467),\n",
      " (40, 0.051337713894268895),\n",
      " (41, 0.19179937531042132),\n",
      " (42, 0.15677337222991514),\n",
      " (43, 0.09995693419749453),\n",
      " (44, 0.47412414231885786)]\n"
     ]
    }
   ],
   "source": [
    "model = models.TfidfModel(corpus)\n",
    "corpus_tfidf = model[corpus]\n",
    "\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gGGWpZiDINEY"
   },
   "source": [
    "## Running LDA using Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1435
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9712,
     "status": "error",
     "timestamp": 1559986451407,
     "user": {
      "displayName": "EJ LEE",
      "photoUrl": "",
      "userId": "07041686333152487261"
     },
     "user_tz": -540
    },
    "id": "jAX7nFW3INEa",
    "outputId": "650a139f-37cb-4558-f880-0d53179f86e6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-21:\n",
      "Process ForkPoolWorker-23:\n",
      "Process ForkPoolWorker-22:\n",
      "Process ForkPoolWorker-24:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/gensim/models/ldamulticore.py\", line 333, in worker_e_step\n",
      "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py\", line 725, in do_estep\n",
      "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py\", line 676, in inference\n",
      "    gammad = self.alpha + expElogthetad * np.dot(cts / phinorm, expElogbetad.T)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/gensim/models/ldamulticore.py\", line 333, in worker_e_step\n",
      "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/gensim/models/ldamulticore.py\", line 333, in worker_e_step\n",
      "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py\", line 725, in do_estep\n",
      "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py\", line 677, in inference\n",
      "    Elogthetad = dirichlet_expectation(gammad)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 103, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py\", line 725, in do_estep\n",
      "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py\", line 676, in inference\n",
      "    gammad = self.alpha + expElogthetad * np.dot(cts / phinorm, expElogbetad.T)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/gensim/models/ldamulticore.py\", line 333, in worker_e_step\n",
      "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py\", line 725, in do_estep\n",
      "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py\", line 677, in inference\n",
      "    Elogthetad = dirichlet_expectation(gammad)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-29db1a79490f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlda_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLdaMulticore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopicN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, workers, chunksize, passes, batch, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, random_state, minimum_probability, minimum_phi_value, per_word_topics, dtype)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_every\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mgamma_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum_probability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminimum_probability\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mminimum_phi_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminimum_phi_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_word_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mper_word_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         )\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_dir_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, corpus, chunks_as_numpy)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;31m# wait for all outstanding jobs to finish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mqueue_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                 \u001b[0mprocess_result_queue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreallen\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlencorpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36mprocess_result_queue\u001b[0;34m(force)\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \"\"\"\n\u001b[1;32m    267\u001b[0m                 \u001b[0mmerged_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m                     \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                     \u001b[0mqueue_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mempty\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_WaitSelector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobject_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m                 \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEVENT_READ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mregister\u001b[0;34m(self, fileobj, events, data)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0mpoll_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mEVENT_READ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mregister\u001b[0;34m(self, fileobj, events, data)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid events: {!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSelectorKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fileobj_lookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fd_to_key\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36m_fileobj_lookup\u001b[0;34m(self, fileobj)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \"\"\"\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_fileobj_to_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0;31m# Do an exhaustive search.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36m_fileobj_to_fd\u001b[0;34m(fileobj)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             raise ValueError(\"Invalid file object: \"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lda_model = gensim.models.LdaMulticore(corpus, num_topics=topicN, id2word=dct, passes=2, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 635,
     "status": "ok",
     "timestamp": 1559984994957,
     "user": {
      "displayName": "EJ LEE",
      "photoUrl": "",
      "userId": "07041686333152487261"
     },
     "user_tz": -540
    },
    "id": "p5F7JXY1INEg",
    "outputId": "641301aa-6454-4961-d54d-ec6910b20171"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.004*\"time\" + 0.003*\"way\" + 0.003*\"could\" + 0.003*\"use\" + 0.003*\"new\" + 0.003*\"work\" + 0.003*\"american\" + 0.003*\"us\" + 0.003*\"state\" + 0.003*\"want\"\n",
      "Topic: 1 Word: 0.005*\"state\" + 0.005*\"republican\" + 0.005*\"time\" + 0.005*\"vote\" + 0.004*\"democrat\" + 0.004*\"elect\" + 0.004*\"new\" + 0.004*\"could\" + 0.003*\"support\" + 0.003*\"want\"\n",
      "Topic: 2 Word: 0.004*\"time\" + 0.003*\"new\" + 0.003*\"way\" + 0.003*\"first\" + 0.003*\"work\" + 0.003*\"thing\" + 0.003*\"call\" + 0.002*\"want\" + 0.002*\"come\" + 0.002*\"know\"\n",
      "Topic: 3 Word: 0.005*\"work\" + 0.004*\"american\" + 0.004*\"time\" + 0.004*\"state\" + 0.003*\"could\" + 0.003*\"countri\" + 0.003*\"news\" + 0.003*\"new\" + 0.003*\"call\" + 0.003*\"first\"\n",
      "Topic: 4 Word: 0.006*\"state\" + 0.004*\"new\" + 0.004*\"work\" + 0.004*\"time\" + 0.004*\"american\" + 0.003*\"us\" + 0.003*\"want\" + 0.003*\"way\" + 0.003*\"use\" + 0.003*\"could\"\n",
      "Topic: 5 Word: 0.005*\"new\" + 0.004*\"us\" + 0.004*\"state\" + 0.004*\"republican\" + 0.003*\"plan\" + 0.003*\"could\" + 0.003*\"obama\" + 0.003*\"govern\" + 0.003*\"tax\" + 0.003*\"way\"\n",
      "Topic: 6 Word: 0.006*\"student\" + 0.004*\"time\" + 0.004*\"school\" + 0.004*\"new\" + 0.003*\"could\" + 0.003*\"state\" + 0.003*\"us\" + 0.003*\"work\" + 0.003*\"countri\" + 0.003*\"use\"\n",
      "Topic: 7 Word: 0.005*\"women\" + 0.004*\"new\" + 0.004*\"time\" + 0.003*\"use\" + 0.003*\"could\" + 0.003*\"work\" + 0.003*\"way\" + 0.003*\"thing\" + 0.003*\"us\" + 0.003*\"first\"\n",
      "Topic: 8 Word: 0.005*\"new\" + 0.004*\"state\" + 0.004*\"time\" + 0.004*\"court\" + 0.003*\"us\" + 0.003*\"day\" + 0.003*\"told\" + 0.003*\"case\" + 0.003*\"use\" + 0.003*\"first\"\n",
      "Topic: 9 Word: 0.004*\"use\" + 0.004*\"time\" + 0.004*\"state\" + 0.004*\"way\" + 0.003*\"new\" + 0.003*\"come\" + 0.003*\"work\" + 0.003*\"us\" + 0.003*\"american\" + 0.003*\"could\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lHH8a91RINEp"
   },
   "source": [
    "## Running LDA using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j69Ur5U7i6t4"
   },
   "outputs": [],
   "source": [
    "topicN = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RzPVB1toINEr"
   },
   "outputs": [],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=topicN, id2word=dct, passes=2, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 705,
     "status": "ok",
     "timestamp": 1559987886898,
     "user": {
      "displayName": "EJ LEE",
      "photoUrl": "",
      "userId": "07041686333152487261"
     },
     "user_tz": -540
    },
    "id": "1C8xA1WnINEy",
    "outputId": "66172cf6-d89b-400e-90c6-9af7456babc1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.001*\"rubio\" + 0.001*\"gawker\" + 0.001*\"hogan\" + 0.001*\"parker\" + 0.001*\"cruz\" + 0.001*\"illeg\" + 0.001*\"women\" + 0.001*\"marco\" + 0.001*\"new\" + 0.001*\"denton\"\n",
      "Topic: 1 Word: 0.001*\"abedin\" + 0.001*\"weiner\" + 0.001*\"mail\" + 0.001*\"huma\" + 0.001*\"2017\" + 0.001*\"fbi\" + 0.001*\"senat\" + 0.001*\"rousseff\" + 0.001*\"redact\" + 0.001*\"american\"\n",
      "Topic: 2 Word: 0.002*\"gun\" + 0.001*\"news\" + 0.001*\"user\" + 0.001*\"media\" + 0.001*\"2016\" + 0.001*\"new\" + 0.001*\"check\" + 0.001*\"attack\" + 0.001*\"film\" + 0.001*\"post\"\n",
      "Topic: 3 Word: 0.001*\"women\" + 0.001*\"ryan\" + 0.001*\"bill\" + 0.001*\"state\" + 0.001*\"plan\" + 0.001*\"american\" + 0.001*\"work\" + 0.001*\"gainor\" + 0.001*\"countri\" + 0.001*\"obamacar\"\n",
      "Topic: 4 Word: 0.003*\"zika\" + 0.002*\"cartel\" + 0.002*\"border\" + 0.001*\"migrant\" + 0.001*\"mexican\" + 0.001*\"abort\" + 0.001*\"mosquito\" + 0.001*\"cair\" + 0.001*\"parenthood\" + 0.001*\"agent\"\n",
      "Topic: 5 Word: 0.001*\"wasserman\" + 0.001*\"schultz\" + 0.001*\"parenthood\" + 0.001*\"yahoo\" + 0.001*\"debbi\" + 0.001*\"democrat\" + 0.001*\"state\" + 0.001*\"plan\" + 0.001*\"daleiden\" + 0.001*\"administr\"\n",
      "Topic: 6 Word: 0.001*\"rahami\" + 0.001*\"attack\" + 0.001*\"gun\" + 0.001*\"2017\" + 0.001*\"star\" + 0.001*\"percent\" + 0.001*\"countri\" + 0.001*\"state\" + 0.001*\"vote\" + 0.001*\"pope\"\n",
      "Topic: 7 Word: 0.001*\"protest\" + 0.001*\"student\" + 0.001*\"republican\" + 0.001*\"democrat\" + 0.001*\"ryan\" + 0.001*\"court\" + 0.001*\"black\" + 0.001*\"clark\" + 0.001*\"hurrican\" + 0.001*\"state\"\n",
      "Topic: 8 Word: 0.001*\"parenthood\" + 0.001*\"abort\" + 0.001*\"apprehens\" + 0.001*\"cartel\" + 0.001*\"percent\" + 0.001*\"border\" + 0.001*\"roug\" + 0.001*\"women\" + 0.001*\"state\" + 0.001*\"mexican\"\n",
      "Topic: 9 Word: 0.002*\"rubio\" + 0.001*\"trade\" + 0.001*\"china\" + 0.001*\"republican\" + 0.001*\"cruz\" + 0.001*\"tpp\" + 0.001*\"campaign\" + 0.001*\"obama\" + 0.001*\"vote\" + 0.001*\"democrat\"\n",
      "Topic: 10 Word: 0.001*\"obama\" + 0.001*\"brazilian\" + 0.001*\"republican\" + 0.001*\"china\" + 0.001*\"franci\" + 0.001*\"janeiro\" + 0.001*\"2017\" + 0.001*\"women\" + 0.001*\"state\" + 0.001*\"muslim\"\n",
      "Topic: 11 Word: 0.002*\"obama\" + 0.002*\"percent\" + 0.002*\"cruz\" + 0.002*\"hillari\" + 0.002*\"republican\" + 0.002*\"state\" + 0.002*\"vote\" + 0.002*\"campaign\" + 0.002*\"democrat\" + 0.001*\"american\"\n",
      "Topic: 12 Word: 0.002*\"cartel\" + 0.001*\"coahuila\" + 0.001*\"border\" + 0.001*\"gunmen\" + 0.001*\"mexican\" + 0.001*\"tamaulipa\" + 0.001*\"state\" + 0.001*\"news\" + 0.001*\"lo\" + 0.001*\"victim\"\n",
      "Topic: 13 Word: 0.001*\"abedin\" + 0.001*\"clooney\" + 0.001*\"gun\" + 0.001*\"pope\" + 0.001*\"weiner\" + 0.001*\"christian\" + 0.001*\"state\" + 0.001*\"huma\" + 0.001*\"attack\" + 0.001*\"law\"\n",
      "Topic: 14 Word: 0.002*\"assang\" + 0.001*\"wikileak\" + 0.001*\"pirro\" + 0.001*\"senat\" + 0.001*\"haiti\" + 0.001*\"guzman\" + 0.001*\"court\" + 0.001*\"plan\" + 0.001*\"white\" + 0.001*\"fbi\"\n",
      "Topic: 15 Word: 0.001*\"student\" + 0.001*\"school\" + 0.001*\"migrant\" + 0.001*\"black\" + 0.001*\"protest\" + 0.001*\"democrat\" + 0.001*\"vote\" + 0.001*\"hillari\" + 0.001*\"mr\" + 0.001*\"campaign\"\n",
      "Topic: 16 Word: 0.001*\"transgend\" + 0.001*\"gun\" + 0.001*\"health\" + 0.001*\"2017\" + 0.001*\"bathroom\" + 0.001*\"obama\" + 0.001*\"state\" + 0.001*\"game\" + 0.001*\"white\" + 0.001*\"new\"\n",
      "Topic: 17 Word: 0.001*\"school\" + 0.001*\"gun\" + 0.001*\"attack\" + 0.001*\"obama\" + 0.001*\"cruz\" + 0.001*\"democrat\" + 0.001*\"vote\" + 0.001*\"news\" + 0.001*\"republican\" + 0.001*\"fire\"\n",
      "Topic: 18 Word: 0.001*\"senat\" + 0.001*\"scarborough\" + 0.001*\"court\" + 0.001*\"republican\" + 0.001*\"hillari\" + 0.001*\"scalia\" + 0.001*\"democrat\" + 0.001*\"nomine\" + 0.001*\"giuliani\" + 0.001*\"attack\"\n",
      "Topic: 19 Word: 0.002*\"kain\" + 0.001*\"hillari\" + 0.001*\"sander\" + 0.001*\"obama\" + 0.001*\"russian\" + 0.001*\"democrat\" + 0.001*\"campaign\" + 0.001*\"republican\" + 0.001*\"russia\" + 0.001*\"2016\"\n",
      "Topic: 20 Word: 0.002*\"romney\" + 0.001*\"mitt\" + 0.001*\"illeg\" + 0.001*\"white\" + 0.001*\"republican\" + 0.001*\"obamacar\" + 0.001*\"media\" + 0.001*\"law\" + 0.001*\"news\" + 0.001*\"state\"\n",
      "Topic: 21 Word: 0.001*\"student\" + 0.001*\"women\" + 0.001*\"speech\" + 0.001*\"attack\" + 0.001*\"news\" + 0.001*\"univers\" + 0.001*\"state\" + 0.001*\"media\" + 0.001*\"event\" + 0.001*\"musk\"\n",
      "Topic: 22 Word: 0.001*\"state\" + 0.001*\"new\" + 0.001*\"student\" + 0.001*\"arrest\" + 0.001*\"wall\" + 0.001*\"vote\" + 0.001*\"huffman\" + 0.001*\"republican\" + 0.001*\"illeg\" + 0.001*\"2017\"\n",
      "Topic: 23 Word: 0.001*\"democrat\" + 0.001*\"budget\" + 0.001*\"page\" + 0.001*\"uranium\" + 0.001*\"news\" + 0.001*\"white\" + 0.001*\"plan\" + 0.001*\"pinkett\" + 0.001*\"republican\" + 0.001*\"perino\"\n",
      "Topic: 24 Word: 0.003*\"percent\" + 0.002*\"poll\" + 0.001*\"hillari\" + 0.001*\"obama\" + 0.001*\"democrat\" + 0.001*\"republican\" + 0.001*\"state\" + 0.001*\"support\" + 0.001*\"new\" + 0.001*\"nomine\"\n"
     ]
    }
   ],
   "source": [
    "fw = open(\"model_result.txt\", 'a')\n",
    "\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "fw.write('%s-%s-%s\\t' % ( now.year, now.month, now.day ))\n",
    "\n",
    "fw.write(fname+\" \"+str(topicN)+'\\n')\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    fw.write('Topic: {} Word: {}\\n'.format(idx, topic))\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))\n",
    "fw.write('\\n')\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h11XO9YJINE7"
   },
   "source": [
    "## Save LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1045,
     "status": "ok",
     "timestamp": 1559987892038,
     "user": {
      "displayName": "EJ LEE",
      "photoUrl": "",
      "userId": "07041686333152487261"
     },
     "user_tz": -540
    },
    "id": "vmaoKSfAINE9",
    "outputId": "7d1fefe5-2117-4363-9f21-88cd568a1726"
   },
   "outputs": [],
   "source": [
    "lda_model_tfidf.save(save_name+str(topicN)+\".model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "twIQavfRINFE"
   },
   "source": [
    "num_topics 10,15,20,25,30\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "gGGWpZiDINEY"
   ],
   "name": "LDA.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
